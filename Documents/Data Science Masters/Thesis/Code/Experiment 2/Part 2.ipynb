{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prolog</th>\n",
       "      <th>Search</th>\n",
       "      <th>Adversarial_Search</th>\n",
       "      <th>Constraint_Satisfaction_Or_Propagation</th>\n",
       "      <th>Logic</th>\n",
       "      <th>Knowledge_Representation</th>\n",
       "      <th>Planning</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total_percentage</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>24.117647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.764706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>45.294118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>53.529412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prolog  Search  Adversarial_Search  Constraint_Satisfaction_Or_Propagation  \\\n",
       "0     1.5     5.5                 0.0                                     5.0   \n",
       "1     0.0     2.0                 2.0                                     0.5   \n",
       "2     0.0     6.5                 4.0                                     3.0   \n",
       "3     0.0     9.0                 5.0                                     7.0   \n",
       "4     2.5     8.0                 5.0                                    11.5   \n",
       "\n",
       "   Logic  Knowledge_Representation  Planning  Total  Total_percentage  Pass  \n",
       "0    2.0                       4.5       2.0   20.5         24.117647     0  \n",
       "1    0.0                       0.0       0.0    4.5          5.294118     0  \n",
       "2    5.0                       5.0       3.5   27.0         31.764706     0  \n",
       "3    7.0                       2.5       8.0   38.5         45.294118     0  \n",
       "4    4.0                       7.0       7.5   45.5         53.529412     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by loading the uploaded file and inspecting its contents to understand the structure of the data.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file\n",
    "data = pd.read_excel('C:/Users/Prachi/Documents/Data Science Masters/Thesis/student_score_per_topic_with_total.xlsx')\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Squared Error (MSE)</th>\n",
       "      <th>R-squared (R2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8.908869e-29</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>2.058889e+01</td>\n",
       "      <td>0.924718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>6.280457e+00</td>\n",
       "      <td>0.977036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Mean Squared Error (MSE)  R-squared (R2)\n",
       "0        Linear Regression              8.908869e-29        1.000000\n",
       "1  Decision Tree Regressor              2.058889e+01        0.924718\n",
       "2  Random Forest Regressor              6.280457e+00        0.977036"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "# Define features (all topic scores) and target (Total score)\n",
    "features = ['Prolog', 'Search', 'Adversarial_Search', 'Constraint_Satisfaction_Or_Propagation', 'Logic', 'Knowledge_Representation', 'Planning']\n",
    "X = data[features]\n",
    "y = data['Total']\n",
    "\n",
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 2: Model Development\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Decision Tree Regressor\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Step 3: Model Evaluation\n",
    "# Calculate evaluation metrics for each model\n",
    "\n",
    "# Linear Regression Metrics\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "# Decision Tree Regressor Metrics\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "# Random Forest Regressor Metrics\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Collect results in a DataFrame to display\n",
    "results_regression_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree Regressor', 'Random Forest Regressor'],\n",
    "    'Mean Squared Error (MSE)': [mse_linear, mse_tree, mse_rf],\n",
    "    'R-squared (R2)': [r2_linear, r2_tree, r2_rf]\n",
    "})\n",
    "\n",
    "\n",
    "# Display the DataFrame for reference\n",
    "results_regression_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "1                                  Search    3.832063\n",
      "4                                   Logic    3.777177\n",
      "6                                Planning    3.426629\n",
      "5                Knowledge_Representation    3.356420\n",
      "3  Constraint_Satisfaction_Or_Propagation    3.252547\n",
      "2                      Adversarial_Search    1.571657\n",
      "0                                  Prolog    1.395366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Linear Regression on the standardized features\n",
    "linear_model_temp = LinearRegression()\n",
    "linear_model_temp.fit(X_scaled, y)\n",
    "\n",
    "# Get the absolute values of the coefficients to determine importance\n",
    "feature_importance = abs(linear_model_temp.coef_)\n",
    "\n",
    "# Create a DataFrame to rank the features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Model  Mean Squared Error (MSE)  \\\n",
      "0        Linear Regression (Top 3 Features)                 17.084974   \n",
      "1  Decision Tree Regressor (Top 3 Features)                 40.848148   \n",
      "2  Random Forest Regressor (Top 3 Features)                 24.414088   \n",
      "\n",
      "   R-squared (R2)  \n",
      "0        0.937530  \n",
      "1        0.850641  \n",
      "2        0.910731  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Feature Selection - Choosing the top 3 features based on Linear Regression coefficients\n",
    "# Fit a Linear Regression model to determine feature importance\n",
    "linear_model_temp = LinearRegression()\n",
    "linear_model_temp.fit(X_train, y_train)\n",
    "\n",
    "# Get the absolute values of the coefficients to determine importance\n",
    "feature_importance = abs(linear_model_temp.coef_)\n",
    "\n",
    "# Create a DataFrame to rank the features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 3 features\n",
    "top_3_features = feature_importance_df['Feature'].head(3).tolist()\n",
    "\n",
    "# Step 2: Data Preparation with Top 3 Features\n",
    "# Define features and target with the top 3 features\n",
    "X_top_3 = data[top_3_features]\n",
    "\n",
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "X_train_top_3, X_test_top_3, y_train_top_3, y_test_top_3 = train_test_split(X_top_3, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Model Development with Top 3 Features\n",
    "\n",
    "# Linear Regression with Top 3 Features\n",
    "linear_model_top_3 = LinearRegression()\n",
    "linear_model_top_3.fit(X_train_top_3, y_train_top_3)\n",
    "y_pred_linear_top_3 = linear_model_top_3.predict(X_test_top_3)\n",
    "\n",
    "# Decision Tree Regressor with Top 3 Features\n",
    "tree_model_top_3 = DecisionTreeRegressor(random_state=42)\n",
    "tree_model_top_3.fit(X_train_top_3, y_train_top_3)\n",
    "y_pred_tree_top_3 = tree_model_top_3.predict(X_test_top_3)\n",
    "\n",
    "# Random Forest Regressor with Top 3 Features\n",
    "rf_model_top_3 = RandomForestRegressor(random_state=42)\n",
    "rf_model_top_3.fit(X_train_top_3, y_train_top_3)\n",
    "y_pred_rf_top_3 = rf_model_top_3.predict(X_test_top_3)\n",
    "\n",
    "# Step 4: Model Evaluation with Top 3 Features\n",
    "# Calculate evaluation metrics for each model\n",
    "\n",
    "# Linear Regression Metrics with Top 3 Features\n",
    "mse_linear_top_3 = mean_squared_error(y_test_top_3, y_pred_linear_top_3)\n",
    "r2_linear_top_3 = r2_score(y_test_top_3, y_pred_linear_top_3)\n",
    "\n",
    "# Decision Tree Regressor Metrics with Top 3 Features\n",
    "mse_tree_top_3 = mean_squared_error(y_test_top_3, y_pred_tree_top_3)\n",
    "r2_tree_top_3 = r2_score(y_test_top_3, y_pred_tree_top_3)\n",
    "\n",
    "# Random Forest Regressor Metrics with Top 3 Features\n",
    "mse_rf_top_3 = mean_squared_error(y_test_top_3, y_pred_rf_top_3)\n",
    "r2_rf_top_3 = r2_score(y_test_top_3, y_pred_rf_top_3)\n",
    "\n",
    "# Collect results in a DataFrame to display\n",
    "results_regression_top_3_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression (Top 3 Features)', 'Decision Tree Regressor (Top 3 Features)', 'Random Forest Regressor (Top 3 Features)'],\n",
    "    'Mean Squared Error (MSE)': [mse_linear_top_3, mse_tree_top_3, mse_rf_top_3],\n",
    "    'R-squared (R2)': [r2_linear_top_3, r2_tree_top_3, r2_rf_top_3]\n",
    "})\n",
    "\n",
    "\n",
    "# Display the DataFrame for reference\n",
    "print(results_regression_top_3_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}                                             Model  Mean Squared Error (MSE)  \\\n",
      "0  Tuned Random Forest Regressor (Top 3 Features)                 24.972342   \n",
      "\n",
      "   R-squared (R2)  \n",
      "0         0.90869  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Define the hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Step 2: Set up GridSearchCV for Random Forest Regressor\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Step 3: Fit the model with the top 3 features\n",
    "grid_search_rf.fit(X_train_top_3, y_train_top_3)\n",
    "\n",
    "# Step 4: Get the best parameters and evaluate the best model on the test set\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf_tuned = best_rf_model.predict(X_test_top_3)\n",
    "\n",
    "# Calculate evaluation metrics for the tuned Random Forest model\n",
    "mse_rf_tuned = mean_squared_error(y_test_top_3, y_pred_rf_tuned)\n",
    "r2_rf_tuned = r2_score(y_test_top_3, y_pred_rf_tuned)\n",
    "\n",
    "# Display the best parameters and model performance\n",
    "best_params = grid_search_rf.best_params_\n",
    "results_rf_tuned_df = pd.DataFrame({\n",
    "    'Model': ['Tuned Random Forest Regressor (Top 3 Features)'],\n",
    "    'Mean Squared Error (MSE)': [mse_rf_tuned],\n",
    "    'R-squared (R2)': [r2_rf_tuned]\n",
    "})\n",
    "\n",
    "\n",
    "# Display the best parameters and the DataFrame for reference\n",
    "print(best_params, results_rf_tuned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': True}                                                Model  \\\n",
      "0  Randomized Tuned Random Forest Regressor (Top ...   \n",
      "\n",
      "   Mean Squared Error (MSE)  R-squared (R2)  \n",
      "0                 25.605884        0.906373  \n"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries since the Python environment has restarted\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Define features and target (top 3 features from previous analysis)\n",
    "top_3_features = ['Search', 'Knowledge_Representation', 'Logic']\n",
    "X_top_3 = data[top_3_features]\n",
    "y = data['Total']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_top_3, X_test_top_3, y_train_top_3, y_test_top_3 = train_test_split(X_top_3, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the hyperparameter distribution for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV for Random Forest Regressor\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20,  # Number of parameter settings that are sampled\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with the top 3 features\n",
    "random_search_rf.fit(X_train_top_3, y_train_top_3)\n",
    "\n",
    "# Get the best parameters and evaluate the best model on the test set\n",
    "best_rf_model_random = random_search_rf.best_estimator_\n",
    "y_pred_rf_random_tuned = best_rf_model_random.predict(X_test_top_3)\n",
    "\n",
    "# Calculate evaluation metrics for the tuned Random Forest model\n",
    "mse_rf_random_tuned = mean_squared_error(y_test_top_3, y_pred_rf_random_tuned)\n",
    "r2_rf_random_tuned = r2_score(y_test_top_3, y_pred_rf_random_tuned)\n",
    "\n",
    "# Display the best parameters and model performance\n",
    "best_params_random = random_search_rf.best_params_\n",
    "results_rf_random_tuned_df = pd.DataFrame({\n",
    "    'Model': ['Randomized Tuned Random Forest Regressor (Top 3 Features)'],\n",
    "    'Mean Squared Error (MSE)': [mse_rf_random_tuned],\n",
    "    'R-squared (R2)': [r2_rf_random_tuned]\n",
    "})\n",
    "\n",
    "\n",
    "# Display the best parameters and the DataFrame for reference\n",
    "print(best_params_random, results_rf_random_tuned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Model  Mean Squared Error (MSE)  \\\n",
      "0  Tuned Random Forest Regressor (Top 3 Features)                 24.972342   \n",
      "1    Gradient Boosting Regressor (Top 3 Features)                 25.283464   \n",
      "2    Tuned Random Forest Regressor (All Features)                  8.687915   \n",
      "\n",
      "   R-squared (R2)  \n",
      "0        0.908690  \n",
      "1        0.907552  \n",
      "2        0.968233  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train Gradient Boosting Regressor with default parameters for comparison\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train_top_3, y_train_top_3)\n",
    "y_pred_gb = gb_model.predict(X_test_top_3)\n",
    "\n",
    "# Step 2: Evaluate the Gradient Boosting Regressor\n",
    "mse_gb = mean_squared_error(y_test_top_3, y_pred_gb)\n",
    "r2_gb = r2_score(y_test_top_3, y_pred_gb)\n",
    "\n",
    "# Step 3: Train Random Forest with all available features for comparison\n",
    "X_all_features = data[features]\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_model_all_features = RandomForestRegressor(**best_params, random_state=42)\n",
    "rf_model_all_features.fit(X_train_all, y_train_all)\n",
    "y_pred_rf_all_features = rf_model_all_features.predict(X_test_all)\n",
    "\n",
    "# Evaluate the Random Forest Regressor trained with all features\n",
    "mse_rf_all_features = mean_squared_error(y_test_all, y_pred_rf_all_features)\n",
    "r2_rf_all_features = r2_score(y_test_all, y_pred_rf_all_features)\n",
    "\n",
    "# Step 4: Collect results in a DataFrame to display\n",
    "results_improvement_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Tuned Random Forest Regressor (Top 3 Features)',\n",
    "        'Gradient Boosting Regressor (Top 3 Features)',\n",
    "        'Tuned Random Forest Regressor (All Features)'\n",
    "    ],\n",
    "    'Mean Squared Error (MSE)': [mse_rf_tuned, mse_gb, mse_rf_all_features],\n",
    "    'R-squared (R2)': [r2_rf_tuned, r2_gb, r2_rf_all_features]\n",
    "})\n",
    "\n",
    "# Display the results to the user\n",
    "\n",
    "# Display the DataFrame for reference\n",
    "print(results_improvement_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "6                                Planning         1.0\n",
      "4                                   Logic         1.0\n",
      "1                                  Search         1.0\n",
      "2                      Adversarial_Search         1.0\n",
      "5                Knowledge_Representation         1.0\n",
      "3  Constraint_Satisfaction_Or_Propagation         1.0\n",
      "0                                  Prolog         1.0\n"
     ]
    }
   ],
   "source": [
    "linear_model_temp = LinearRegression()\n",
    "linear_model_temp.fit(X_train, y_train)\n",
    "\n",
    "# Get the absolute values of the coefficients to determine importance\n",
    "feature_importance = linear_model_temp.coef_\n",
    "\n",
    "# Create a DataFrame to rank the features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
