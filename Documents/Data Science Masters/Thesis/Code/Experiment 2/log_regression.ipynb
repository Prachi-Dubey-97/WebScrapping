{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_excel('C:/Users/Prachi/Documents/Data Science Masters/Thesis/student_score_per_topic_with_total.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all score columns to numeric (assuming score columns are named 'Score1', 'Score2', ...)\n",
    "score_columns = [col for col in data.columns if 'sums' in col]\n",
    "data[score_columns] = data[score_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing values with the mean (or zero, or median)\n",
    "data[score_columns] = data[score_columns].fillna(data[score_columns].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sums_1  sums_2  sums_3  sums_4  sums_5  sums_6  sums_7  total  \\\n",
      "0       1.5     5.5     0.0     5.0     2.0     4.5     2.0   20.5   \n",
      "1       0.0     2.0     2.0     0.5     0.0     0.0     0.0    4.5   \n",
      "2       0.0     6.5     4.0     3.0     5.0     5.0     3.5   27.0   \n",
      "3       0.0     9.0     5.0     7.0     7.0     2.5     8.0   38.5   \n",
      "4       2.5     8.0     5.0    11.5     4.0     7.0     7.5   45.5   \n",
      "..      ...     ...     ...     ...     ...     ...     ...    ...   \n",
      "443     2.5    13.5     5.0     9.0    12.5     8.5     1.5   52.5   \n",
      "444     3.0    11.0     5.0     5.5     0.0     5.0     7.0   36.5   \n",
      "445     1.0    13.0     5.0     9.0     6.5    10.0     5.5   50.0   \n",
      "446     5.0    17.5     3.0     4.5    11.0     8.0     4.5   53.5   \n",
      "447     5.0    18.0     5.0    11.0    12.7     9.5     7.5   68.7   \n",
      "\n",
      "     total_percentage  \n",
      "0           24.117647  \n",
      "1            5.294118  \n",
      "2           31.764706  \n",
      "3           45.294118  \n",
      "4           53.529412  \n",
      "..                ...  \n",
      "443         61.764706  \n",
      "444         42.941176  \n",
      "445         58.823529  \n",
      "446         62.941176  \n",
      "447         80.823529  \n",
      "\n",
      "[448 rows x 9 columns]\n",
      "['sums_1', 'sums_2', 'sums_3', 'sums_4', 'sums_5', 'sums_6', 'sums_7']\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(score_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sums_1  sums_2  sums_3  sums_4  sums_5  sums_6  sums_7  total  \\\n",
      "0       1.5     5.5     0.0     5.0     2.0     4.5     2.0   20.5   \n",
      "1       0.0     2.0     2.0     0.5     0.0     0.0     0.0    4.5   \n",
      "2       0.0     6.5     4.0     3.0     5.0     5.0     3.5   27.0   \n",
      "3       0.0     9.0     5.0     7.0     7.0     2.5     8.0   38.5   \n",
      "4       2.5     8.0     5.0    11.5     4.0     7.0     7.5   45.5   \n",
      "..      ...     ...     ...     ...     ...     ...     ...    ...   \n",
      "443     2.5    13.5     5.0     9.0    12.5     8.5     1.5   52.5   \n",
      "444     3.0    11.0     5.0     5.5     0.0     5.0     7.0   36.5   \n",
      "445     1.0    13.0     5.0     9.0     6.5    10.0     5.5   50.0   \n",
      "446     5.0    17.5     3.0     4.5    11.0     8.0     4.5   53.5   \n",
      "447     5.0    18.0     5.0    11.0    12.7     9.5     7.5   68.7   \n",
      "\n",
      "     total_percentage  Pass  \n",
      "0           24.117647     0  \n",
      "1            5.294118     0  \n",
      "2           31.764706     0  \n",
      "3           45.294118     1  \n",
      "4           53.529412     1  \n",
      "..                ...   ...  \n",
      "443         61.764706     1  \n",
      "444         42.941176     1  \n",
      "445         58.823529     1  \n",
      "446         62.941176     1  \n",
      "447         80.823529     1  \n",
      "\n",
      "[448 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a binary 'Pass' column based on the passing percentage, e.g., 40%\n",
    "passing_score = 34\n",
    "data['Pass'] = (data['total'] >= passing_score).astype(int)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Select features and target\n",
    "X = data[score_columns]  # Features are the scores in different topics\n",
    "y = data['Pass']          # Target is the binary Pass/Fail outcome\n",
    "2\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9888888888888889\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        46\n",
      "           1       1.00      0.98      0.99        44\n",
      "\n",
      "    accuracy                           0.99        90\n",
      "   macro avg       0.99      0.99      0.99        90\n",
      "weighted avg       0.99      0.99      0.99        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred1 = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred2 = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: factor_analyzer in c:\\users\\prachi\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from factor_analyzer) (1.5.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from factor_analyzer) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from factor_analyzer) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from factor_analyzer) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from pandas->factor_analyzer) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from pandas->factor_analyzer) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from scikit-learn->factor_analyzer) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from scikit-learn->factor_analyzer) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prachi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->factor_analyzer) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install factor_analyzer\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FactorAnalyzer(n_factors=1, rotation=None, rotation_kwargs={})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FactorAnalyzer</label><div class=\"sk-toggleable__content\"><pre>FactorAnalyzer(n_factors=1, rotation=None, rotation_kwargs={})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FactorAnalyzer(n_factors=1, rotation=None, rotation_kwargs={})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = FactorAnalyzer(rotation=None, n_factors=1)\n",
    "fa.fit(data[score_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5140286 ]\n",
      " [-0.77420371]\n",
      " [-0.63787271]\n",
      " [-0.8010909 ]\n",
      " [-0.82785433]\n",
      " [-0.74719972]\n",
      " [-0.77418818]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the loadings of each variable\n",
    "print(fa.loadings_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_factors = ['sums_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sums_7\n",
      "17      4.0\n",
      "66      2.0\n",
      "176     3.5\n",
      "247     1.5\n",
      "31      6.0\n",
      "..      ...\n",
      "106    10.0\n",
      "270     8.0\n",
      "348    10.0\n",
      "435     5.5\n",
      "102     5.5\n",
      "\n",
      "[358 rows x 1 columns] 17     0\n",
      "66     0\n",
      "176    0\n",
      "247    1\n",
      "31     0\n",
      "      ..\n",
      "106    1\n",
      "270    0\n",
      "348    1\n",
      "435    0\n",
      "102    1\n",
      "Name: Pass, Length: 358, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming 'selected_factors' are the columns resulting from factor analysis you chose\n",
    "X = data[selected_factors]\n",
    "y = data['Pass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.18710285 0.78084712 0.54325809 0.47811383 0.38546324 0.33540328\n",
      " 0.28981159]\n"
     ]
    }
   ],
   "source": [
    "# Get Eigenvalues and scree plot to decide the number of factors\n",
    "ev, v = fa.get_eigenvalues()\n",
    "print(ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21192259 0.54372466]\n",
      " [0.50281716 0.6190542 ]\n",
      " [0.5541869  0.34356023]\n",
      " [0.45057333 0.70965502]\n",
      " [0.58345214 0.59512088]\n",
      " [0.73926493 0.32755769]\n",
      " [0.73054092 0.36885046]\n",
      " [0.74955809 0.68406745]\n",
      " [0.74955809 0.68406745]\n",
      " [0.64860185 0.56806926]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You might also use rotation to improve interpretability\n",
    "fa = FactorAnalyzer(rotation=\"varimax\", n_factors=2)\n",
    "fa.fit(data)\n",
    "print(fa.loadings_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
