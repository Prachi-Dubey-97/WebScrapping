{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "1                                  Search    2.290782\n",
      "5                Knowledge_Representation    2.037486\n",
      "4                                   Logic    1.975297\n",
      "6                                Planning    1.858909\n",
      "3  Constraint_Satisfaction_Or_Propagation    1.795093\n",
      "2                      Adversarial_Search    1.144585\n",
      "0                                  Prolog    0.634842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = 'C:/Users/Prachi/Documents/Data Science Masters/Thesis/Code/Experiment 3/student_score_per_topic_with_total.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "data.head()\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['Total', 'Total_percentage', 'Pass'])\n",
    "y = data['Pass']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply Logistic Regression with L1 regularization (Lasso)\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
    "logreg_l1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the feature importance (coefficients)\n",
    "feature_importance = np.abs(logreg_l1.coef_[0])\n",
    "\n",
    "# Map the importance back to the feature names\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  RFE_Ranking\n",
      "1                                  Search            1\n",
      "5                Knowledge_Representation            2\n",
      "3  Constraint_Satisfaction_Or_Propagation            3\n",
      "4                                   Logic            4\n",
      "6                                Planning            5\n",
      "2                      Adversarial_Search            6\n",
      "0                                  Prolog            7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Perform Recursive Feature Elimination with Logistic Regression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(solver='liblinear', random_state=42), n_features_to_select=1)\n",
    "rfe_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get RFE rankings\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RFE_Ranking': rfe_selector.ranking_\n",
    "}).sort_values(by='RFE_Ranking')\n",
    "\n",
    "\n",
    "# Display the RFE ranking\n",
    "print(rfe_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n",
      "Precision: 0.9574468085106383\n",
      "Recall: 0.9183673469387755\n",
      "F1 Score: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select top features from L1 regularization and RFE\n",
    "top_features_l1 = ['Search', 'Knowledge_Representation', 'Logic']  # Replace with your actual top features from L1\n",
    "top_features_rfe = ['Search', 'Logic', 'Planning']  # Replace with your actual top features from RFE\n",
    "\n",
    "# Combine these features (you can decide whether to take a union or intersection of the features)\n",
    "selected_features = list(set(top_features_l1).union(set(top_features_rfe)))  # Union of both sets\n",
    "\n",
    "# Step 2: Create a reduced feature set based on the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Step 3: Train a Logistic Regression model using the reduced feature set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Normal Logistic Regression  0.955556   0.957447  0.918367  0.937500\n",
      "1     L1 Logistic Regression   0.955556   0.938776  0.938776  0.938776\n",
      "2      L2 Logistic Regression  0.955556   0.957447  0.918367  0.937500\n",
      "3               Decision Tree  0.903704   0.891304  0.836735  0.863158\n",
      "4               Random Forest  0.925926   0.914894  0.877551  0.895833\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Define features and target (using only top 2 features)\n",
    "top_2_features = ['Search', 'Knowledge_Representation', 'Logic', 'Planning']\n",
    "#top_2_features = ['Search', 'Knowledge_Representation']\n",
    "X = data[top_2_features]\n",
    "y = data['Pass']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Normal Logistic Regression (no regularization)\n",
    "logreg_normal = LogisticRegression( random_state=42)\n",
    "logreg_normal.fit(X_train_scaled, y_train)\n",
    "y_pred_normal = logreg_normal.predict(X_test_scaled)\n",
    "\n",
    "# Logistic Regression with L1 (Lasso)\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
    "logreg_l1.fit(X_train_scaled, y_train)\n",
    "y_pred_l1 = logreg_l1.predict(X_test_scaled)\n",
    "\n",
    "# Logistic Regression with L2 (Ridge)\n",
    "logreg_l2 = LogisticRegression(penalty='l2', solver='lbfgs', random_state=42)\n",
    "logreg_l2.fit(X_train_scaled, y_train)\n",
    "y_pred_l2 = logreg_l2.predict(X_test_scaled)\n",
    "\n",
    "# Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Normal Logistic Regression\n",
    "precision_normal = precision_score(y_test, y_pred_normal)\n",
    "recall_normal = recall_score(y_test, y_pred_normal)\n",
    "accuracy_normal = accuracy_score(y_test, y_pred_normal)\n",
    "f1_normal = f1_score(y_test, y_pred_normal)\n",
    "\n",
    "# Calculate metrics for L1 Logistic Regression\n",
    "precision_l1 = precision_score(y_test, y_pred_l1)\n",
    "recall_l1 = recall_score(y_test, y_pred_l1)\n",
    "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "f1_l1 = f1_score(y_test, y_pred_l1)\n",
    "\n",
    "# Calculate metrics for L2 Logistic Regression\n",
    "precision_l2 = precision_score(y_test, y_pred_l2)\n",
    "recall_l2 = recall_score(y_test, y_pred_l2)\n",
    "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "f1_l2 = f1_score(y_test, y_pred_l2)\n",
    "\n",
    "# Calculate metrics for Decision Tree\n",
    "precision_tree = precision_score(y_test, y_pred_tree)\n",
    "recall_tree = recall_score(y_test, y_pred_tree)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "f1_tree = f1_score(y_test, y_pred_tree)\n",
    "\n",
    "# Calculate metrics for Random Forest\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Collect results in a DataFrame to display\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Normal Logistic Regression', 'L1 Logistic Regression ', 'L2 Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_normal, accuracy_l1, accuracy_l2, accuracy_tree, accuracy_rf],\n",
    "    'Precision': [precision_normal, precision_l1, precision_l2, precision_tree, precision_rf],\n",
    "    'Recall': [recall_normal, recall_l1, recall_l2, recall_tree, recall_rf],\n",
    "    'F1 Score': [f1_normal, f1_l1, f1_l2, f1_tree, f1_rf]\n",
    "})\n",
    "\n",
    "# Display the results to the user\n",
    "\n",
    "# Display the DataFrame for reference\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Tuned L2 Logistic Regression  0.955556   0.957447  0.918367  0.937500\n",
      "1           Tuned Decision Tree  0.903704   0.891304  0.836735  0.863158\n",
      "2           Tuned Random Forest  0.933333   0.934783  0.877551  0.905263\n",
      "3             Gradient Boosting  0.911111   0.893617  0.857143  0.875000\n",
      "                        Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Normal Logistic Regression  0.955556   0.957447  0.918367  0.937500\n",
      "1     L1 Logistic Regression   0.955556   0.938776  0.938776  0.938776\n",
      "2      L2 Logistic Regression  0.955556   0.957447  0.918367  0.937500\n",
      "3               Decision Tree  0.903704   0.891304  0.836735  0.863158\n",
      "4               Random Forest  0.925926   0.914894  0.877551  0.895833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prachi\\AppData\\Local\\Temp\\ipykernel_1732\\1655382925.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_improved_df = results_improved_df.append({\n",
      "C:\\Users\\Prachi\\AppData\\Local\\Temp\\ipykernel_1732\\1655382925.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_improved_df = results_improved_df.append({\n",
      "C:\\Users\\Prachi\\AppData\\Local\\Temp\\ipykernel_1732\\1655382925.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_improved_df = results_improved_df.append({\n",
      "C:\\Users\\Prachi\\AppData\\Local\\Temp\\ipykernel_1732\\1655382925.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_improved_df = results_improved_df.append({\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression with GridSearchCV\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "logreg_l2_tuned = GridSearchCV(LogisticRegression(penalty='l2', solver='lbfgs', random_state=42), param_grid_lr, cv=5)\n",
    "logreg_l2_tuned.fit(X_train_scaled, y_train)\n",
    "y_pred_l2_tuned = logreg_l2_tuned.predict(X_test_scaled)\n",
    "\n",
    "# Hyperparameter tuning for Decision Tree with GridSearchCV\n",
    "param_grid_tree = {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10]}\n",
    "tree_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_tree, cv=5)\n",
    "tree_tuned.fit(X_train, y_train)\n",
    "y_pred_tree_tuned = tree_tuned.predict(X_test)\n",
    "\n",
    "# Random Forest hyperparameter tuning\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n",
    "rf_tuned = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred_rf_tuned = rf_tuned.predict(X_test)\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned models and Gradient Boosting\n",
    "models = {\n",
    "    'Tuned L2 Logistic Regression': y_pred_l2_tuned,\n",
    "    'Tuned Decision Tree': y_pred_tree_tuned,\n",
    "    'Tuned Random Forest': y_pred_rf_tuned,\n",
    "    'Gradient Boosting': y_pred_gb\n",
    "}\n",
    "\n",
    "results_improved_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "for model_name, y_pred in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results_improved_df = results_improved_df.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Display the improved results\n",
    "print(results_improved_df)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
